import pandas as pd  ##import necessary libraries
import numpy as np
import math
import matplotlib.pyplot as plt




import tensorflow as tf
%load_ext tensorboard

import warnings
warnings.filterwarnings('ignore')

import os
import datetime as dt
df = pd.read_csv('NIFTY50.csv')
import pywt
close_prices = df['Close'].values

# Perform DWT using the Haar wavelet ('db1')
wavelet = 'db1'
coeffs = pywt.wavedec(close_prices, wavelet, level=2)

# Set threshold (using the universal threshold method)
# The threshold can be adjusted depending on the level of noise and desired smoothness
threshold = np.sqrt(2 * np.log(len(close_prices))) * (np.median(np.abs(coeffs[-1])) / 0.6745)

# Apply soft thresholding to detail coefficients
# coeffs[0] are the approximation coefficients (low frequency)
# coeffs[1:] are the detail coefficients (high frequency)
denoised_coeffs = [pywt.threshold(c, threshold, mode='soft') if i > 0 else c for i, c in enumerate(coeffs)]

# Reconstruct the denoised signal
denoised_signal = pywt.waverec(denoised_coeffs, wavelet)

# Import the libraries
from pandas_datareader import data as web
import pandas as pd
!pip install numpy==1.19.5
import numpy as np
import datetime

import warnings
import matplotlib.pyplot as plt
import pandas_datareader as dr
%matplotlib inline


def df_to_X_y(df, window_size=5):
  df_as_np = np.array(df)
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
    row = [r for r in df_as_np[i:i+window_size]]
    X.append(row)
    label = df_as_np[i+window_size][3]
    y.append(label)
  return np.array(X), np.array(y)
window_size= 5
X1, y1 = df_to_X_y(df)
X1.shape, y1.shape
# Normalize the dataset
# Feature scaling
### LSTM are sensitive to the scale of the data. so we apply MinMax scaler
##splitting dataset into train and test split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, mean_absolute_error
from keras.models import Sequential
# from tensorflow.keras.layers import CuDNNLSTM
from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Input, Multiply, Reshape
from keras.layers import TimeDistributed, Conv1D, MaxPooling1D, Flatten
#from keras.optimizers import SGD
# Define input shapes for the data
from keras.regularizers import l1, l2, l1_l2

model1 = Sequential()

model1.add(GRU(units, return_sequences=True, input_shape = (train_data.shape[1],train_data.shape[2])))


model1.add(Conv1D(32, kernel_size=1, activation='relu', padding='same'))
model1.add(MaxPooling1D(pool_size = 1))
model1.add(Flatten())


model1.add(Dense(1))
#model1.add(Dense(units=1, activation='softmax'))
model1.summary()
model1.compile(optimizer=Nadam, loss='mse')
history=model1.fit(train_data, train_label, validation_data=(val_data, val_label), epochs=100, batch_size=128, verbose=True)
#plot prediction
a,b,predictions,y = plot_predictions1(model1, test_data_re, test_label)
def return_rmse(Actual,Prediction):
    mae = mean_absolute_error(Actual,Prediction)
    rmse = mean_squared_error(Actual,Prediction, squared= False)
    R2 = r2_score(Actual,Prediction)
    mape = mean_absolute_percentage_error(Actual,Prediction)
    maxerror = max_error(Actual,Prediction)
    Medae = median_absolute_error(Actual,Prediction)

    print("Mean absolute error, MAE = {}".format(mae))
    print("Root mean squared error, RMSE = {}".format(rmse))
    print("Mean absolute percentage error, MAPE = {}".format(mape))
    print("R2, R2 = {}".format(R2))
    print("Max Error, Maximum Error = {}".format(maxerror))
    print("Median absolute error, MedAE = {}".format(Medae))
return_rmse(y,predictions)
